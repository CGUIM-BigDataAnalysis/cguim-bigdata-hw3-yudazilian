---
title: "長庚大學 大數據分析方法 作業三"
output: github_document
---
## 網站資料爬取
```{r}
#這是R Code Chunk
library(rvest) ##第一次使用要先安裝 install.packages("rvest")
ptt_movie = 'https://www.ptt.cc/bbs/movie/index'
html_tail = '.html'
pages = seq(from=1, to=1000, by=2)

authors <- c() 
titles  <- c()
numbers <- c()

for(page in pages[1:10]) {
  
  url <-paste0(ptt_movie, toString(page), '.html')
  
  posts<-read_html(url)%>%html_nodes('.r-ent')
  
  for (post in posts) {
    
    author <- post%>%html_nodes('.author')%>%html_text()
    title  <- post%>%html_nodes('.title a')%>%html_text()
    number <- post%>%html_nodes('.nrec span')%>%html_text()
    
    if (identical(number, character(0))) {
      numbers <- c(numbers, '0')
    } else {
      numbers <- c(numbers, number)
    }
    
    authors <- c(authors, author)
    titles  <- c(titles, title)
    
    
  }
}

data_output <- data.frame(Authors=authors, Titles=titles, Numbers=numbers)
```

## 爬蟲結果呈現
```{r}
#這是R Code Chunk
knitr::kable(data_output) ##請將iris取代為上個步驟中產生的爬蟲資料資料框
```

## 解釋爬蟲結果 
```{r}
#這是R Code Chunk
dim(data_output)
nrow(data_output)
```

總共抓了200篇，欄位有3。

```{r}
#這是R Code Chunk
sort(table(data_output$Author), decreasing = T)
```

PO文數的作者為firewalker與filmwalker分別為11篇與10篇。

懶得懶得懶得寫人工結論
